version: '3'

services:

  dev:
    image: flink:1.17.0
    environment:
      FLINK_PROPERTIES: "jobmanager.rpc.address: localhost"
      POETRY_VIRTUALENVS_IN_PROJECT: "true"
      ELASTICSEARCH_USERNAME: "user"
      ELASTICSEARCH_PASSWORD: "password"
      ELASTICSEARCH_ENDPOINT: "http://localhost:9200"
      KAFKA_BOOTSTRAP_SERVER_HOSTNAME: "localhost"
      KAFKA_BOOTSTRAP_SERVER_PORT: "9092"
      KAFKA_CONSUMER_GROUP_ID: "13"
      KAFKA_PRODUCER_GROUP_ID: "13"
      KAFKA_ERROR_TOPIC_NAME: "DEAD_LETTER_BOX"
      KAFKA_SOURCE_TOPIC_NAME: "ENRICHED_ENTITIES"
    command: taskmanager
    volumes:
      - ..:/workspace:cached
      - checkpoints:/tmp/flink-checkpoints-directory

  pyflink-jobmanager:
    image: pyflink:0.1
    environment:
      FLINK_PROPERTIES: "jobmanager.rpc.address: localhost"
      POETRY_VIRTUALENVS_IN_PROJECT: "true"
    command: jobmanager
    volumes:
      - checkpoints:/tmp/flink-checkpoints-directory
    network_mode: service:dev
    restart: unless-stopped

  # setup:
  #   image: docker.elastic.co/elasticsearch/elasticsearch:8.2.3
  #   container_name: es-setup
  #   volumes:
  #     - certs:/usr/share/elasticsearch/config/certs
  #   user: "0"
  #   command: >
  #     bash -c '
  #       if [ ! -f certs/ca.zip ]; then
  #         echo "Creating CA";
  #         bin/elasticsearch-certutil ca --silent --pem -out config/certs/ca.zip;
  #         unzip config/certs/ca.zip -d config/certs;
  #       fi;
  #       if [ ! -f certs/certs.zip ]; then
  #         echo "Creating certs";
  #         echo -ne \
  #         "instances:\n"\
  #         "  - name: elasticsearch\n"\
  #         "    dns:\n"\
  #         "      - elasticsearch\n"\
  #         "      - localhost\n"\
  #         "    ip:\n"\
  #         "      - 127.0.0.1\n"\
  #         > config/certs/instances.yml;
  #         bin/elasticsearch-certutil cert --silent --pem -out config/certs/certs.zip --in config/certs/instances.yml --ca-cert config/certs/ca/ca.crt --ca-key config/certs/ca/ca.key;
  #         unzip config/certs/certs.zip -d config/certs;
  #       fi;
  #       echo "Setting file permissions"
  #       chown -R root:root config/certs;
  #       find . -type d -exec chmod 750 \{\} \;;
  #       find . -type f -exec chmod 640 \{\} \;;
  #       echo "Waiting for Elasticsearch availability";
  #       until curl -s --cacert config/certs/ca/ca.crt https://elasticsearch:9200 | grep -q "missing authentication credentials"; do sleep 30; done;
  #       echo "Setting kibana_system password";
  #       until curl -s -X POST --cacert config/certs/ca/ca.crt -u elastic:elasticpw -H "Content-Type: application/json" https://elasticsearch:9200/_security/user/kibana_system/_password -d "{\"password\":\"kibanapw\"}" | grep -q "^{}"; do sleep 10; done;
  #       echo "All done!";
  #     '
  #   healthcheck:
  #     test: ["CMD-SHELL", "[ -f config/certs/elasticsearch/elasticsearch.crt ]"]
  #     interval: 1s
  #     timeout: 5s
  #     retries: 120

  # elasticsearch:
  #   depends_on:
  #     setup:
  #       condition: service_healthy
  #   image: docker.elastic.co/elasticsearch/elasticsearch:8.2.3
  #   container_name: elasticsearch
  #   volumes:
  #     - certs:/usr/share/elasticsearch/config/certs
  #     - esdata:/usr/share/elasticsearch/data
  #   # ports:
  #   #   - ${ES_PORT}:9200
  #   environment:
  #     # - node.name=elasticsearch
  #     - node.name=elasticsearch
  #     - cluster.name=docker-cluster
  #     - discovery.type=single-node
  #     # - cluster.initial_master_nodes=elasticsearch
  #     - ELASTIC_PASSWORD=elasticpw
  #     - bootstrap.memory_lock=true
  #     - xpack.security.enabled=true
  #     - xpack.security.http.ssl.enabled=true
  #     - xpack.security.http.ssl.key=certs/elasticsearch/elasticsearch.key
  #     - xpack.security.http.ssl.certificate=certs/elasticsearch/elasticsearch.crt
  #     - xpack.security.http.ssl.certificate_authorities=certs/ca/ca.crt
  #     - xpack.security.http.ssl.verification_mode=certificate
  #     - xpack.security.transport.ssl.enabled=true
  #     - xpack.security.transport.ssl.key=certs/elasticsearch/elasticsearch.key
  #     - xpack.security.transport.ssl.certificate=certs/elasticsearch/elasticsearch.crt
  #     - xpack.security.transport.ssl.certificate_authorities=certs/ca/ca.crt
  #     - xpack.security.transport.ssl.verification_mode=certificate
  #     - xpack.license.self_generated.type=basic
  #   # mem_limit: 1073741824
  #   volumes:
  #     - esdata:/usr/share/elasticsearch/data
  #   network_mode: service:dev
  #   restart: unless-stopped
  #   ulimits:
  #     memlock:
  #       soft: -1
  #       hard: -1
  #   healthcheck:
  #     test:
  #       [
  #           "CMD-SHELL",
  #           "curl -s --cacert config/certs/ca/ca.crt https://localhost:9200 | grep -q 'missing authentication credentials'",
  #       ]
  #     interval: 10s
  #     timeout: 10s
  #     retries: 120

  # kibana:
  #   depends_on:
  #     elasticsearch:
  #       condition: service_healthy
  #   image: docker.elastic.co/kibana/kibana:8.2.3
  #   container_name: kibana
  #   volumes:
  #     - certs:/usr/share/kibana/config/certs
  #     - kibanadata:/usr/share/kibana/data
  #   # ports:
  #   #   - ${KIBANA_PORT}:5601
  #   environment:
  #     - ELASTIC_PASSWORD=elasticpw
  #     - KIBANA_PASSWORD=kibanapw
  #     - SERVERNAME=kibana
  #     - ELASTICSEARCH_HOSTS=https://elasticsearch:9200
  #     - ELASTICSEARCH_USERNAME=kibana_system
  #     - ELASTICSEARCH_PASSWORD=kibanapw
  #     - ELASTICSEARCH_SSL_CERTIFICATEAUTHORITIES=config/certs/ca/ca.crt
  #     - ENTERPRISESEARCH_HOST=http://enterprisesearch:3002
  #     - SERVER_PUBLICBASEURL=http://localhost:5601/kibana
  #     - SERVER_BASEPATH=/kibana
  #   volumes:
  #     - kibanadata:/usr/share/kibana/data
  #   network_mode: service:dev
  #   restart: unless-stopped
  #   # mem_limit: ${MEM_LIMIT}
  #   healthcheck:
  #     test:
  #       [
  #           "CMD-SHELL",
  #           "curl -s -I http://localhost:5601 | grep -q 'HTTP/1.1 302 Found'",
  #       ]
  #     interval: 10s
  #     timeout: 10s
  #     retries: 120

  # enterprisesearch:
  #   depends_on:
  #     elasticsearch:
  #       condition: service_healthy
  #     kibana:
  #       condition: service_healthy
  #   image: docker.elastic.co/enterprise-search/enterprise-search:8.2.3
  #   container_name: enterprisesearch
  #   volumes:
  #     - certs:/usr/share/enterprise-search/config/certs
  #     - enterprisesearchdata:/usr/share/enterprise-search/config
  #   # ports:
  #   #   - ${ENTERPRISE_SEARCH_PORT}:3002
  #   environment:
  #     - ENCRYPTION_KEYS=secret
  #     - SERVERNAME=enterprisesearch
  #     - secret_management.encryption_keys=[secret]
  #     - allow_es_settings_modification=true
  #     - elasticsearch.host=https://elasticsearch:9200
  #     - elasticsearch.username=elastic
  #     - elasticsearch.password=elasticpw
  #     - elasticsearch.ssl.enabled=true
  #     - elasticsearch.ssl.certificate_authority=/usr/share/enterprise-search/config/certs/ca/ca.crt
  #     - kibana.external_url=http://kibana:5601
  #   network_mode: service:dev
  #   restart: unless-stopped
  #   #mem_limit: ${MEM_LIMIT}
  #   healthcheck:
  #     test:
  #       [
  #           "CMD-SHELL",
  #           "curl -s -I http://localhost:3002 | grep -q 'HTTP/1.1 302 Found'",
  #       ]
  #     interval: 10s
  #     timeout: 10s
  #     retries: 120


  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.2.3
    container_name: elasticsearch
    environment:
      - node.name=elasticsearch
      - cluster.name=docker-cluster
      - discovery.type=single-node
      - "ELASTICSEARCH_USERNAME=user"
      - "ELASTICSEARCH_PASSWORD=password"
      - ELASTICSEARCH_ENDPOINT=http://localhost:9200
    volumes:
      - esdata:/usr/share/elasticsearch/data
    network_mode: service:dev
    restart: unless-stopped

  kibana:
    image: docker.elastic.co/kibana/kibana:8.2.3
    container_name: kibana
    environment:
      - node.name=kibana
      - ELASTICSEARCH_HOSTS=https://elasticsearch:9200
      - ELASTICSEARCH_USERNAME=user
      - ELASTICSEARCH_PASSWORD=password
    volumes:
      - kibanadata:/usr/share/kibana/data
    network_mode: service:dev
    restart: unless-stopped

  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.2
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    network_mode: service:dev
    restart: unless-stopped

  kafka-broker:
    image: confluentinc/cp-kafka:7.3.2
    container_name: kafka-broker
    depends_on:
      - zookeeper
    volumes:
      - code:/code
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: localhost:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
    network_mode: service:dev
    restart: unless-stopped

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    depends_on:
      - kafka-broker
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=localhost:9092
      - SERVER_PORT=8082
    network_mode: service:dev
    restart: unless-stopped



volumes:
  esdata:
  checkpoints:
  code:
  kibanadata:
  certs:
  #enterprisesearchdata:
